\section*{Wissenschaftlicher Bezug}
\label{sec:scientific-relevance}

\guillemotleft Recurrent Neuronal Networks\guillemotright{} (kurz RNN) erfreuen sich seit neuster Zeit hoher Beliebtheit, weil sie als Grundlage von Intelligenzen zur Verarbeitung
von natürlichsprachlichem Text gute Resultate liefern.
Sie sind Gegenstand aktueller Forschung.
RNNs können neben vielen anderen spezifischen Aufgaben auch dazu verwendet werden, Modelle zu konstruieren, die fähig sind,
Sequenzen zu lernen und wiederzugeben.
Dies erlaubt der Intelligenz im wahrsten Sinne, sich einen «Dialekt» anzueignen, ihn nach dem Training wiederzugeben und so neue Wortsequenzen zu erschaffen.
Prominente Beispiele solcher \guillemotleft Character-based-RNNs\guillemotright{} sind u.a.
der Shakespeare-Generator\footnote{http://karpathy.github.io/2015/05/21/rnn-effectiveness/} oder DeepDrumpf\footnote{https://twitter.com/deepdrumpf}.
